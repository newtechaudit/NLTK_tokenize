{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "«Липецкая область, Липецк, Правобережный округ, микрорайон Сокол, ул. Сельских Строителей, 82\n",
      "\n",
      "\n",
      "Продам клетку. 1 199 руб. Купил попугая и с ним клетку, корм, витамины и камни для желудка. Но попугай через 2 дня после покупки улетел, а нового заводить не хочу. Поэтому продаю) Все что на фото входит в стоимость.\n",
      "Телефон для связи 8-123-456-78-90,\n",
      "Антон Сергеевич П.»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = '''«Липецкая область, Липецк, Правобережный округ, микрорайон Сокол, ул. Сельских Строителей, 82\n",
    "\n",
    "\n",
    "Продам клетку. 1 199 руб. Купил попугая и с ним клетку, корм, витамины и камни для желудка. Но попугай через 2 дня после покупки улетел, а нового заводить не хочу. Поэтому продаю) Все что на фото входит в стоимость.\n",
    "Телефон для связи 8-123-456-78-90,\n",
    "Антон Сергеевич П.»\n",
    "'''\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "['BlanklineTokenizer', 'LegalitySyllableTokenizer', 'LineTokenizer', 'MWETokenizer', 'NLTKWordTokenizer', 'PunktSentenceTokenizer', 'RegexpTokenizer', 'ReppTokenizer', 'SExprTokenizer', 'SpaceTokenizer', 'StanfordSegmenter', 'SyllableTokenizer', 'TabTokenizer', 'TextTilingTokenizer', 'ToktokTokenizer', 'TreebankWordTokenizer', 'TweetTokenizer', 'WhitespaceTokenizer', 'WordPunctTokenizer']\n"
     ]
    }
   ],
   "source": [
    "tokenizer_list = [tkn for tkn in dir(tokenize) if tkn[0].isupper()]\n",
    "print(len(tokenizer_list), tokenizer_list, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "? tokenize.RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Липецкая', 'Липецк', 'Правобережный', 'Сокол', 'Сельских', 'Строителей', 'Продам', 'Купил', 'Но', 'Поэтому', 'Все', 'Телефон', 'Антон', 'Сергеевич']\n"
     ]
    }
   ],
   "source": [
    "pattern = '[А-Я]\\w+'\n",
    "tok = tokenize.RegexpTokenizer(pattern, gaps=False)\n",
    "print(tok.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Липецкая', 'Липецк', 'Правобережный', 'Сокол', 'Сельских', 'Строителей', 'Продам', 'Купил', 'Но', 'Поэтому', 'Все', 'Телефон', 'Антон', 'Сергеевич']\n"
     ]
    }
   ],
   "source": [
    "print(re.findall(pattern, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "['«Липецкая', 'область,', 'Липецк,', 'Правобережный', 'округ,', 'микрорайон', 'Сокол,', 'ул.', 'Сельских', 'Строителей,', '82', 'Продам', 'клетку.', '1', '199', 'руб.', 'Купил', 'попугая', 'и', 'с', 'ним', 'клетку,', 'корм,', 'витамины', 'и', 'камни', 'для', 'желудка.', 'Но', 'попугай', 'через', '2', 'дня', 'после', 'покупки', 'улетел,', 'а', 'нового', 'заводить', 'не', 'хочу.', 'Поэтому', 'продаю)', 'Все', 'что', 'на', 'фото', 'входит', 'в', 'стоимость.', 'Телефон', 'для', 'связи', '8-123-456-78-90,', 'Антон', 'Сергеевич', 'П.»']\n"
     ]
    }
   ],
   "source": [
    "tok = tokenize.WhitespaceTokenizer()\n",
    "print(len(tok.tokenize(text)))\n",
    "print(tok.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['«Липецкая область, Липецк, Правобережный округ, микрорайон Сокол, ул. Сельских Строителей, 82',\n",
       " 'Продам клетку. 1 199 руб. Купил попугая и с ним клетку, корм, витамины и камни для желудка. Но попугай через 2 дня после покупки улетел, а нового заводить не хочу. Поэтому продаю) Все что на фото входит в стоимость.\\nТелефон для связи 8-123-456-78-90,\\nАнтон Сергеевич П.»\\n']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok = tokenize.BlanklineTokenizer()\n",
    "print(len(tok.tokenize(text)))\n",
    "tok.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n",
      "['«', 'Липецкая', 'область', ',', 'Липецк', ',', 'Правобережный', 'округ', ',', 'микрорайон', 'Сокол', ',', 'ул', '.', 'Сельских', 'Строителей', ',', '82', 'Продам', 'клетку', '.', '1', '199', 'руб', '.', 'Купил', 'попугая', 'и', 'с', 'ним', 'клетку', ',', 'корм', ',', 'витамины', 'и', 'камни', 'для', 'желудка', '.', 'Но', 'попугай', 'через', '2', 'дня', 'после', 'покупки', 'улетел', ',', 'а', 'нового', 'заводить', 'не', 'хочу', '.', 'Поэтому', 'продаю', ')', 'Все', 'что', 'на', 'фото', 'входит', 'в', 'стоимость', '.', 'Телефон', 'для', 'связи', '8', '-', '123', '-', '456', '-', '78', '-', '90', ',', 'Антон', 'Сергеевич', 'П', '.»']\n"
     ]
    }
   ],
   "source": [
    "tok = tokenize.WordPunctTokenizer()\n",
    "print(len(tok.tokenize(text)))\n",
    "print(tok.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "? tokenize.SExprTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "['«Липецкая', 'область,', 'Липецк,', 'Правобережный', 'округ,', 'микрорайон', 'Сокол,', 'ул.', 'Сельских', 'Строителей,', '82', 'Продам', 'клетку.', '1', '199', 'руб.', 'Купил', 'попугая', 'и', 'с', 'ним', 'клетку,', 'корм,', 'витамины', 'и', 'камни', 'для', 'желудка.', 'Но', 'попугай', 'через', '2', 'дня', 'после', 'покупки', 'улетел,', 'а', 'нового', 'заводить', 'не', 'хочу.', 'Поэтому', 'продаю', ')', ' Все что на фото входит в стоимость.\\nТелефон для связи 8-123-456-78-90,\\nАнтон Сергеевич П.»\\n']\n"
     ]
    }
   ],
   "source": [
    "tok = tokenize.SExprTokenizer(strict=False)\n",
    "print(len(tok.tokenize(text)))\n",
    "print(tok.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "['(a + b / (2 + y))', '*', 'c', '-', 'x', ')', '+', '25', '/', '(87 )', 'jj', ')', 'sdv', '(vs s']\n"
     ]
    }
   ],
   "source": [
    "txt = '(a + b / (2 + y)) * c - x) + 25 / (87 ) jj) sdv (vs s'\n",
    "tok = tokenize.SExprTokenizer(strict=False)\n",
    "print(len(tok.tokenize(txt)))\n",
    "print(tok.tokenize(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "? tokenize.SpaceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = 'Для подготовки данных при решении задач обработки естественного языка (англ. Natural Processing Language, NLP) в машинном обучении используются специальные обработчики исходного текста'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "['Для', 'подготовки', 'данных', 'при', 'решении', 'задач', 'обработки', 'естественного', 'языка', '(англ.', 'Natural', 'Processing', 'Language,', 'NLP)', 'в', 'машинном', 'обучении', 'используются', 'специальные', 'обработчики', 'исходного', 'текста']\n"
     ]
    }
   ],
   "source": [
    "tok = tokenize.SpaceTokenizer()\n",
    "print(len(tok.tokenize(txt)))\n",
    "print(tok.tokenize(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "['Для', 'подготовки', 'данных', 'при', 'решении', 'задач', 'обработки', 'естественного', 'языка', '(англ.', 'Natural', 'Processing', 'Language,', 'NLP)', 'в', 'машинном', 'обучении', 'используются', 'специальные', 'обработчики', 'исходного', 'текста']\n"
     ]
    }
   ],
   "source": [
    "print(len(txt.split(' ')))\n",
    "print(txt.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "['«Липецкая область, Липецк, Правобережный округ, микрорайон Сокол, ул. Сельских Строителей, 82\\n\\n\\nПродам клетку. 1 199 руб. Купил попугая и с ним клетку, корм, витамины и камни для желудка. Но попугай через 2 дня после покупки улетел, а нового заводить не хочу. Поэтому продаю) Все что на фото входит в стоимость.\\nТелефон для связи 8-123-456-78-90,\\nАнтон Сергеевич П.»\\n']\n"
     ]
    }
   ],
   "source": [
    "tok = tokenize.TabTokenizer()\n",
    "print(len(tok.tokenize(text)))\n",
    "print(tok.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "? tokenize.LegalitySyllableTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n",
      "['«', 'Липецкая', 'область', ',', 'Липецк', ',', 'Правобережный', 'округ', ',', 'микрорайон', 'Сокол', ',', 'ул', '.', 'Сельских', 'Строителей', ',', '82', 'Продам', 'клетку', '.', '1', '199', 'руб', '.', 'Купил', 'попугая', 'и', 'с', 'ним', 'клетку', ',', 'корм', ',', 'витамины', 'и', 'камни', 'для', 'желудка', '.', 'Но', 'попугай', 'через', '2', 'дня', 'после', 'покупки', 'улетел', ',', 'а', 'нового', 'заводить', 'не', 'хочу', '.', 'Поэтому', 'продаю', ')', 'Все', 'что', 'на', 'фото', 'входит', 'в', 'стоимость', '.', 'Телефон', 'для', 'связи', '8', '-', '123', '-', '456', '-', '78', '-', '90', ',', 'Антон', 'Сергеевич', 'П', '.»']\n"
     ]
    }
   ],
   "source": [
    "tok = tokenize.WordPunctTokenizer()\n",
    "print(len(tok.tokenize(text)))\n",
    "print(tok.tokenize(text))\n",
    "text_words = tok.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['«', 'Липецкая', 'область', ',', 'Липецк', ',', 'Правобережный', 'округ', ',', 'микрорайон', 'Сокол', ',', 'ул', '.', 'Сельских', 'Строителей', ',', '82', 'Продам', 'клетку', '.', '1', '199', 'руб', '.', 'Купил', 'попугая', 'и', 'с', 'ним', 'клетку', ',', 'корм', ',', 'витамины', 'и', 'камни', 'для', 'желудка', '.', 'Но', 'попугай', 'через', '2', 'дня', 'после', 'покупки', 'улетел', ',', 'а', 'нового', 'заводить', 'не', 'хочу', '.', 'Поэтому', 'продаю', ')', 'Все', 'что', 'на', 'фото', 'входит', 'в', 'стоимость', '.', 'Телефон', 'для', 'связи', '8', '-', '123', '-', '456', '-', '78', '-', '90', ',', 'Антон', 'Сергеевич', 'П', '.»']\n"
     ]
    }
   ],
   "source": [
    "print(text_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dict.opcorpora.txt', 'r', encoding='utf-8') as f:\n",
    "    all_line = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5924131"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1\\n', 'ЁЖ\\tNOUN,anim,masc sing,nomn\\n', 'ЕЖА\\tNOUN,anim,masc sing,gent\\n']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_line[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_words = [line.split('\\t')[0].lower() for line in all_line if len(line.split('\\t')) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5140577\n"
     ]
    }
   ],
   "source": [
    "print(len(clear_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ёж',\n",
       " 'ежа',\n",
       " 'ежу',\n",
       " 'ежа',\n",
       " 'ежом',\n",
       " 'еже',\n",
       " 'ежи',\n",
       " 'ежей',\n",
       " 'ежам',\n",
       " 'ежей',\n",
       " 'ежами',\n",
       " 'ежах',\n",
       " 'ёж',\n",
       " 'ежа',\n",
       " 'ежу']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_words[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Ли', 'пецк', 'ая'], ['о', 'бласть'], ['Ли', 'пецк'], ['Пра', 'во', 'бе', 'реж', 'ный'], ['о', 'круг'], ['ми', 'кро', 'рай', 'он'], ['Со', 'кол'], ['Сель', 'ских'], ['Стро', 'и', 'те', 'лей'], ['Про', 'дам'], ['клет', 'ку'], ['199'], ['руб'], ['Ку', 'пил'], ['по', 'пуг', 'ая'], ['ним'], ['клет', 'ку'], ['корм'], ['ви', 'та', 'ми', 'ны'], ['ка', 'мни'], ['д', 'ля'], ['же', 'луд', 'ка'], ['по', 'пу', 'гай'], ['че', 'рез'], ['д', 'ня'], ['по', 'сле'], ['по', 'куп', 'ки'], ['у', 'ле', 'тел'], ['но', 'во', 'го'], ['за', 'во', 'дить'], ['хо', 'чу'], ['По', 'э', 'то', 'му'], ['прод', 'аю'], ['Все'], ['ч', 'то'], ['фо', 'то'], ['в', 'хо', 'дит'], ['сто', 'и', 'мость'], ['Те', 'ле', 'фон'], ['д', 'ля'], ['свя', 'зи'], ['123'], ['456'], ['Ан', 'тон'], ['Сер', 'ге', 'е', 'вич']]\n"
     ]
    }
   ],
   "source": [
    "tok = tokenize.LegalitySyllableTokenizer(clear_words, vowels='аеёиоуыэюя')\n",
    "print([tok.tokenize(word) for word in text_words if len(word) > 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['пу', 'те', 'шест', 'вен', 'ник']\n"
     ]
    }
   ],
   "source": [
    "print(tok.tokenize('путешественник'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['кор', 'зи', 'на']\n"
     ]
    }
   ],
   "source": [
    "print(tok.tokenize('корзина'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['воробей', 'гуашь', 'звезды', 'идея', 'индеец', 'Алеша', 'космический', 'пианино', 'черепаха', 'парикмахер', 'бульдог', 'завтрак']\n"
     ]
    }
   ],
   "source": [
    "first_class_words = 'воробей, гуашь, звезды, идея, индеец, Алеша, космический, пианино, черепаха, парикмахер, бульдог, завтрак'.split(', ')\n",
    "print(first_class_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['во', 'ро', 'бей'], ['г', 'уашь'], ['з', 'вез', 'ды'], ['ид', 'ея'], ['инд', 'еец'], ['А', 'ле', 'ша'], ['ко', 'сми', 'че', 'ский'], ['пи', 'а', 'ни', 'но'], ['че', 'ре', 'па', 'ха'], ['па', 'рик', 'ма', 'хер'], ['буль', 'дог'], ['зав', 'трак']]\n"
     ]
    }
   ],
   "source": [
    "print([tok.tokenize(word) for word in first_class_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_line\n",
    "del clear_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "? tokenize.SyllableTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['пу', 'те', 'шес', 'твен', 'ник']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\B-tum\\AppData\\Roaming\\Python\\Python38\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'к'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tok = tokenize.SyllableTokenizer(lang='ru'\n",
    "                                ,sonority_hierarchy=['аеёиоуыэюя', 'мн', 'вфзсжшх', 'рптщ'])\n",
    "print(tok.tokenize('путешественник'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "? tokenize.MWETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 ['Липецкая', 'область', 'вошла', 'в', 'число', 'лидеров', 'в', 'исполнении', 'поручения', 'Президента', 'России', '.']\n",
      "10 ['Липецкая область', 'вошла', 'в', 'число', 'лидеров', 'в', 'исполнении', 'поручения', 'Президента России', '.']\n"
     ]
    }
   ],
   "source": [
    "txt = 'Липецкая область вошла в число лидеров в исполнении поручения Президента России.'\n",
    "tok = tokenize.WordPunctTokenizer()\n",
    "text_words = tok.tokenize(txt)\n",
    "print(len(text_words), text_words)\n",
    "tok = tokenize.MWETokenizer(separator=' ')\n",
    "tok.add_mwe(('Липецкая', 'область'))\n",
    "tok.add_mwe(('Президента', 'России'))\n",
    "print(len(tok.tokenize(text_words)), tok.tokenize(text_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "? tokenize.TextTilingTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopW = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "822"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(r'D:\\Mix\\Books\\videofaq.txt', 'r') as f:\n",
    "    big_text = f.readlines()\n",
    "len(big_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_big_text = ''\n",
    "for el in big_text:\n",
    "    str_big_text += el + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 14\n",
      "1 2 14\n",
      "1 3 14\n",
      "2 1 14\n",
      "2 2 14\n",
      "2 3 14\n",
      "3 1 13\n",
      "3 2 13\n",
      "3 3 13\n",
      "4 1 11\n",
      "4 2 12\n",
      "4 3 12\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "w=[1,2,3,4]\n",
    "k=[1,2,3]\n",
    "for wi, ki in product(w, k):\n",
    "    tok = tokenize.TextTilingTokenizer(w=wi, k=ki, stopwords=stopW)\n",
    "    try:\n",
    "        text_words = tok.tokenize(str_big_text)\n",
    "        if len(text_words) > 1:\n",
    "            print(wi, ki, len(text_words))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "tok = tokenize.TextTilingTokenizer(w=4, k=1, stopwords=stopW)\n",
    "text_words = tok.tokenize(str_big_text)\n",
    "print(len(text_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Frequently Asked Questions (Часто Задаваемые Вопросы) по видеоаппаратуре для IBM PC Создан: 07.04.97 Последняя модификация: 26.08.98 Автор: Евгений Музыченко (Eugene Muzychenko) 2:5000/14@FidoNet, music@spider.nrcde.ru',\n",
       " 'Copyright (C) 1997-98, Eugene V. Muzychenko Все права в отношении данного текста принадлежат автору. При воспроизведении текста или его части сохранение Copyright обяза- тельно. Коммерческое использование допускается только с письмен- ного разрешения автора.')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('\\s+', ' ', text_words[0]).strip(), re.sub('\\s+', ' ', text_words[1]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "? tokenize.ToktokTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "['«Липецкая', 'область', ',', 'Липецк', ',', 'Правобережный', 'округ', ',', 'микрорайон', 'Сокол', ',', 'ул.', 'Сельских', 'Строителей', ',', '82', 'Продам', 'клетку.', '1', '199', 'руб.', 'Купил', 'попугая', 'и', 'с', 'ним', 'клетку', ',', 'корм', ',', 'витамины', 'и', 'камни', 'для', 'желудка.', 'Но', 'попугай', 'через', '2', 'дня', 'после', 'покупки', 'улетел', ',', 'а', 'нового', 'заводить', 'не', 'хочу.', 'Поэтому', 'продаю', ')', 'Все', 'что', 'на', 'фото', 'входит', 'в', 'стоимость.', 'Телефон', 'для', 'связи', '8-123-456-78-90', ',', 'Антон', 'Сергеевич', 'П', '.', '»']\n"
     ]
    }
   ],
   "source": [
    "tok = tokenize.ToktokTokenizer()\n",
    "print(len(tok.tokenize(text)))\n",
    "print(tok.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "? tokenize.TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "['«', 'Липецкая', 'область', ',', 'Липецк', ',', 'Правобережный', 'округ', ',', 'микрорайон', 'Сокол', ',', 'ул', '.', 'Сельских', 'Строителей', ',', '82', 'Продам', 'клетку', '.', '1', '199', 'руб', '.', 'Купил', 'попугая', 'и', 'с', 'ним', 'клетку', ',', 'корм', ',', 'витамины', 'и', 'камни', 'для', 'желудка', '.', 'Но', 'попугай', 'через', '2', 'дня', 'после', 'покупки', 'улетел', ',', 'а', 'нового', 'заводить', 'не', 'хочу', '.', 'Поэтому', 'продаю', ')', 'Все', 'что', 'на', 'фото', 'входит', 'в', 'стоимость', '.', 'Телефон', 'для', 'связи', '8-123-', '456-78-', '90', ',', 'Антон', 'Сергеевич', 'П', '.', '»']\n"
     ]
    }
   ],
   "source": [
    "tok = tokenize.TweetTokenizer()\n",
    "print(len(tok.tokenize(text)))\n",
    "print(tok.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "['<3', ':)', 'This', 'is', 'a', 'cooool', '#dummysmiley', ':', ':-)', ':-P', '<3', 'and', 'some', 'arrows', '<', '>', '->', '<--', ',', '@remy', ':', 'This', 'is', 'waaaaayyyy', 'too', 'much', 'for', 'you', '!', '!', '!']\n",
      "31\n",
      "['<3', ':)', 'this', 'is', 'a', 'cooool', '#dummysmiley', ':', ':-)', ':-P', '<3', 'and', 'some', 'arrows', '<', '>', '->', '<--', ',', '@remy', ':', 'this', 'is', 'waaaaayyyy', 'too', 'much', 'for', 'you', '!', '!', '!']\n",
      "31\n",
      "['<3', ':)', 'this', 'is', 'a', 'coool', '#dummysmiley', ':', ':-)', ':-P', '<3', 'and', 'some', 'arrows', '<', '>', '->', '<--', ',', '@remy', ':', 'this', 'is', 'waaayyy', 'too', 'much', 'for', 'you', '!', '!', '!']\n",
      "30\n",
      "['<3', ':)', 'this', 'is', 'a', 'coool', '#dummysmiley', ':', ':-)', ':-P', '<3', 'and', 'some', 'arrows', '<', '>', '->', '<--', ',', ':', 'this', 'is', 'waaayyy', 'too', 'much', 'for', 'you', '!', '!', '!']\n"
     ]
    }
   ],
   "source": [
    "txt = '<3 :) This is a cooool #dummysmiley: :-) :-P <3 and some arrows < > -> <--, @remy: This is waaaaayyyy too much for you!!!!!!'\n",
    "tok = tokenize.TweetTokenizer(preserve_case=True)\n",
    "print(len(tok.tokenize(txt)))\n",
    "print(tok.tokenize(txt))\n",
    "tok = tokenize.TweetTokenizer(preserve_case=False)\n",
    "print(len(tok.tokenize(txt)))\n",
    "print(tok.tokenize(txt))\n",
    "tok = tokenize.TweetTokenizer(preserve_case=False, reduce_len=True)\n",
    "print(len(tok.tokenize(txt)))\n",
    "print(tok.tokenize(txt))\n",
    "tok = tokenize.TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True)\n",
    "print(len(tok.tokenize(txt)))\n",
    "print(tok.tokenize(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "['Привееет', '!']\n"
     ]
    }
   ],
   "source": [
    "txt = 'Привеееееет!'\n",
    "tok = tokenize.TweetTokenizer(reduce_len=True)\n",
    "print(len(tok.tokenize(txt)))\n",
    "print(tok.tokenize(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "['Привееет', ',']\n"
     ]
    }
   ],
   "source": [
    "txt = 'Привеееееет, @username'\n",
    "tok = tokenize.TweetTokenizer(reduce_len=True, strip_handles=True)\n",
    "print(len(tok.tokenize(txt)))\n",
    "print(tok.tokenize(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "? tokenize.TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "['«Липецкая', 'область', ',', 'Липецк', ',', 'Правобережный', 'округ', ',', 'микрорайон', 'Сокол', ',', 'ул.', 'Сельских', 'Строителей', ',', '82', 'Продам', 'клетку.', '1', '199', 'руб.', 'Купил', 'попугая', 'и', 'с', 'ним', 'клетку', ',', 'корм', ',', 'витамины', 'и', 'камни', 'для', 'желудка.', 'Но', 'попугай', 'через', '2', 'дня', 'после', 'покупки', 'улетел', ',', 'а', 'нового', 'заводить', 'не', 'хочу.', 'Поэтому', 'продаю', ')', 'Все', 'что', 'на', 'фото', 'входит', 'в', 'стоимость.', 'Телефон', 'для', 'связи', '8-123-456-78-90', ',', 'Антон', 'Сергеевич', 'П.»']\n"
     ]
    }
   ],
   "source": [
    "tok = tokenize.TreebankWordTokenizer()\n",
    "print(len(tok.tokenize(text)))\n",
    "print(tok.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 8), (9, 16), (17, 22), (23, 24), (25, 30), (31, 38), (39, 40), (41, 51), (52, 61), (62, 72), (73, 79), (79, 80)]\n"
     ]
    }
   ],
   "source": [
    "txt = 'Липецкая область вошла в число лидеров в исполнении поручения Президента России.'\n",
    "tok = tokenize.TreebankWordTokenizer()\n",
    "print(list(tok.span_tokenize(txt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "? tokenize.NLTKWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "['«', 'Липецкая', 'область', ',', 'Липецк', ',', 'Правобережный', 'округ', ',', 'микрорайон', 'Сокол', ',', 'ул.', 'Сельских', 'Строителей', ',', '82', 'Продам', 'клетку.', '1', '199', 'руб.', 'Купил', 'попугая', 'и', 'с', 'ним', 'клетку', ',', 'корм', ',', 'витамины', 'и', 'камни', 'для', 'желудка.', 'Но', 'попугай', 'через', '2', 'дня', 'после', 'покупки', 'улетел', ',', 'а', 'нового', 'заводить', 'не', 'хочу.', 'Поэтому', 'продаю', ')', 'Все', 'что', 'на', 'фото', 'входит', 'в', 'стоимость.', 'Телефон', 'для', 'связи', '8-123-456-78-90', ',', 'Антон', 'Сергеевич', 'П', '.', '»']\n"
     ]
    }
   ],
   "source": [
    "tok = tokenize.NLTKWordTokenizer()\n",
    "print(len(tok.tokenize(text)))\n",
    "print(tok.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "? tokenize.StanfordSegmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"STANFORD_MODELS\"] = r'C:\\Users\\B-tum\\Курс Анализ текстовых данных\\stanford-segmenter-2020-11-17\\data'\n",
    "os.environ[\"JAVAHOME\"] = r'C:\\Program Files\\Java\\jre1.8.0_261\\bin'\n",
    "os.environ[\"STANFORD_SEGMENTER\"] = r'C:\\Program Files\\Java\\jre1.8.0_261'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-62-4d5bd6229e12>:1: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.parse.corenlp.CoreNLPTokenizer\u001b[0m instead.'\n",
      "  tok = tokenize.StanfordSegmenter(path_to_jar='.\\stanford-segmenter-2020-11-17\\stanford-segmenter-4.2.0.jar')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ل ك ل ش خ ص ا ل ح ق ف ي ا ل ت ع ل م . و ي ج ب ا ن ي ك و ن ا ل ت ع ل ي م ف ي م ر ا ح ل ه ا ل ا و ل ى و ا ل ا س ا س ي ة ع ل ى ا ل ا ق ل ب ا ل م ج ا ن , و ا ن ي ك و ن ا ل ت ع ل ي م ا ل ا و ل ي ا ل ز ا م ي ا و ي ن ب غ ي ا ن ي ع م م ا ل ت ع ل ي م ا ل ف ن ي و ا ل م ه ن ي , و ا ن ي ي س ر ا ل ق ب و ل ل ل ت ع ل ي م ا ل ع ا ل ي ع ل ى ق د م ا ل م س ا و ا ة ا ل ت ا م ة ل ل ج م ي ع و ع ل ى ا س ا س ا ل ك ف ا ء ة\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tok = tokenize.StanfordSegmenter(path_to_jar='.\\stanford-segmenter-2020-11-17\\stanford-segmenter-4.2.0.jar')\n",
    "tok.default_config('ar')\n",
    "sent = 'لكل شخص الحق في التعلم. ويجب أن يكون التعليم في مراحله الأولى والأساسية على الأقل بالمجان، وأن يكون التعليم الأولي إلزاميا وينبغي أن يعمم التعليم الفني والمهني، وأن ييسر القبول للتعليم العالي على قدم المساواة التامة للجميع وعلى أساس الكفاءة'\n",
    "print(tok.segment(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "? tokenize.PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "['Липецкая область вошла в число лидеров в исполнении поручения Президента России.', 'А Рязанская область подписала соглашение о развитии сотрудничества с Республикой Беларусь']\n"
     ]
    }
   ],
   "source": [
    "text = 'Липецкая область вошла в число лидеров в исполнении поручения Президента России. А Рязанская область подписала соглашение о развитии сотрудничества с Республикой Беларусь'\n",
    "tok = nltk.data.load('tokenizers/punkt/russian.pickle')\n",
    "print(len(tok.tokenize(text)))\n",
    "print(tok.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "? tokenize.ReppTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-25089bd30321>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Липецкая область вошла в число лидеров в исполнении поручения Президента России. А Рязанская область подписала соглашение о развитии сотрудничества с Республикой Беларусь'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtok\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReppTokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'c:\\temp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\nltk\\tokenize\\repp.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, repp_dir, encoding)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepp_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepp_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_repptokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepp_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[1;31m# Set a directory to store the temporary files.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworking_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgettempdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\nltk\\tokenize\\repp.py\u001b[0m in \u001b[0;36mfind_repptokenizer\u001b[1;34m(self, repp_dirname)\u001b[0m\n\u001b[0;32m    147\u001b[0m             \u001b[0m_repp_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepp_dirname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_vars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"REPP_TOKENIZER\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;31m# Checks for the REPP binary and erg/repp.set config file.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_repp_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/src/repp\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_repp_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/erg/repp.set\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_repp_dir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "text = 'Липецкая область вошла в число лидеров в исполнении поручения Президента России. А Рязанская область подписала соглашение о развитии сотрудничества с Республикой Беларусь'\n",
    "tok = tokenize.ReppTokenizer(r'c:\\temp')\n",
    "print(len(tok.tokenize(text)))\n",
    "print(tok.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
